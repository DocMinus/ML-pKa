{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Configure Everything We Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict as ddict, OrderedDict as odict\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from rdkit.Chem import PandasTools, AllChem as Chem, Descriptors\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "__author__ = 'Marcel Baltruschat'\n",
    "__copyright__ = 'Copyright © 2020-2023'\n",
    "__license__ = 'MIT'\n",
    "__version__ = '1.1.0'\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)  # Display floats without scientific notation\n",
    "sns.set(palette='bright')  # Set bright style for Seaborn\n",
    "PandasTools.RenderImagesInAllDataFrames()  # Render mol images\n",
    "\n",
    "# In many cases NaN\n",
    "not_used_desc = [\n",
    "    'MaxPartialCharge', \n",
    "    'MinPartialCharge',\n",
    "    'MaxAbsPartialCharge', \n",
    "    'MinAbsPartialCharge', \n",
    "    'BCUT2D_MWHI',\n",
    "    'BCUT2D_MWLOW',\n",
    "    'BCUT2D_CHGHI',\n",
    "    'BCUT2D_CHGLO',\n",
    "    'BCUT2D_LOGPHI',\n",
    "    'BCUT2D_LOGPLOW',\n",
    "    'BCUT2D_MRHI',\n",
    "    'BCUT2D_MRLOW',\n",
    "]\n",
    "\n",
    "# Create a descriptor calculator for all RDKit descriptors except the ones above\n",
    "desc_calc = MolecularDescriptorCalculator([x for x in [x[0] for x in Descriptors.descList] if x not in not_used_desc])\n",
    "print(f'Number of descriptors used: {len(desc_calc.descriptorNames)}/{len(Descriptors.descList)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Cross-Validation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright © 2019 Marcel Baltruschat\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files \n",
    "(the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, \n",
    "publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do \n",
    "so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "Source: https://github.com/czodrowskilab/gafp/tree/master/fp\n",
    "\"\"\"\n",
    "class CVRegressor:\n",
    "    \"\"\"\n",
    "    Regressor that predicts based on predictions of k models from k-fold CV.\n",
    "    Accepts any Scikit-learn-like regressor as base regressor. It trains k models\n",
    "    by doing k-fold CV and stores the individual models. Predictions\n",
    "    on new samples are done by calculating mean predictions from all models.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    est : Any\n",
    "        Scikit-learn (-like) regressor object. Must contain .fit() and .predict() methods.\n",
    "    params : Dict[str, Any]\n",
    "        Regressor parameters\n",
    "    n_folds : int\n",
    "        Number of folds for k-fold\n",
    "    shuffle : bool\n",
    "        Shuffling of data for CV\n",
    "    \"\"\"\n",
    "    __slots__ = ('est', 'params', 'models', 'n_folds', 'shuffle', 'cv_scores')\n",
    "\n",
    "    def __init__(self, est: Any, params: Dict[str, Any], n_folds: int = 5, shuffle: bool = True):\n",
    "        self.est = est\n",
    "        self.params = params\n",
    "        self.models = []\n",
    "        self.n_folds = n_folds\n",
    "        self.shuffle = shuffle\n",
    "        self.cv_scores = ddict(list)\n",
    "\n",
    "    def fit(self, x_data: np.ndarray, y_data: np.ndarray, scoring_funcs: List=(), random_state: int=None) -> None:\n",
    "        \"\"\"\n",
    "        Build a regressor consisting of k-models.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x_data : numpy.ndarray\n",
    "            Training data\n",
    "        y_data : numpy.ndarray\n",
    "            Target values\n",
    "        scoring_funcs : list\n",
    "            List of scoring functions to use for evaluating cross-validation results\n",
    "        random_state : int\n",
    "            Integer to use for seeding the k-fold split\n",
    "        \"\"\"\n",
    "\n",
    "        kf = KFold(n_splits=self.n_folds, shuffle=self.shuffle, random_state=random_state)\n",
    "        kf = kf.split(X=x_data, y=y_data)\n",
    "\n",
    "        # Fit k models and store them\n",
    "        for train_index, test_index in kf:\n",
    "            est_tmp = self.est(**self.params)\n",
    "            est_tmp.fit(x_data[train_index], y_data[train_index])\n",
    "            if scoring_funcs:\n",
    "                test_pred = est_tmp.predict(x_data[test_index])\n",
    "                for sf in scoring_funcs:\n",
    "                    self.cv_scores[str(sf).split(' ')[1]].append(sf(y_data[test_index], test_pred))\n",
    "            self.models.append(est_tmp)\n",
    "\n",
    "    def predict(self, x_data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict using prediction mean from k models.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x_data : numpy.ndarray\n",
    "            Samples to predict\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Predicted values\n",
    "        \"\"\"\n",
    "\n",
    "        return np.mean([m.predict(x_data) for m in self.models], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Helpful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"Helper function\"\"\"\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "def calc_stats_str(pka1, pka2):\n",
    "    \"\"\"Calculates R², MAE and RMSE for two iterables of floats or integers\"\"\"\n",
    "    assert len(pka1) == len(pka2), \"Both iterables must have the same length\"\n",
    "    return f'R²: {r2_score(pka1, pka2):.3f}\\n' \\\n",
    "           f'MAE: {mean_absolute_error(pka1, pka2):.3f}\\n' \\\n",
    "           f'RMSE: {rmse(pka1, pka2):.3f}'\n",
    "\n",
    "def train_cv_model(est_cls, x_data, y_data, params, random_state,\n",
    "                   cv=5, shuffle=True, scaled=False, scoring_funcs=(mean_absolute_error, rmse, r2_score)):\n",
    "    \"\"\"Scales the training data if wanted and trains a cross-validated model\"\"\"\n",
    "    scaler = None\n",
    "    if scaled:\n",
    "        scaler = StandardScaler()\n",
    "        x_data = scaler.fit_transform(x_data)\n",
    "    cvr = CVRegressor(est=est_cls, params=params, n_folds=cv, shuffle=shuffle)\n",
    "    cvr.fit(x_data, y_data, scoring_funcs=scoring_funcs, random_state=random_state)\n",
    "    return cvr, scaler\n",
    "\n",
    "def calc_x_data(mols):\n",
    "    \"\"\"Calculates descriptors and fingerprints for an iterable of RDKit molecules\"\"\"\n",
    "    descs = []  # 196/200 RDKit descriptors\n",
    "    fmorgan3 = []  # 4096 bit\n",
    "    for mol in mols:\n",
    "        descs.append(desc_calc.CalcDescriptors(mol))\n",
    "        fmorgan3.append(Chem.GetMorganFingerprintAsBitVect(mol, radius=3, nBits=4096, useFeatures=True))\n",
    "    descs = np.array(descs)\n",
    "    fmorgan3 = np.array(fmorgan3)\n",
    "    return descs, fmorgan3, np.concatenate([descs, fmorgan3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Loading Precombined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_path = 'datasets/combined_training_datasets_unique.sdf'\n",
    "all_df = PandasTools.LoadSDF(sdf_path).astype(dict(pKa=float, \n",
    "                                                   marvin_atom=int, \n",
    "                                                   marvin_pKa=float), \n",
    "                                              copy=False).set_index('ID', verify_integrity=True)\n",
    "print(f'Initial: {len(all_df)}')\n",
    "all_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show p<i>K</i><sub>a</sub> Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns_major, sns_minor = map(int, sns.__version__.split('.')[:2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100)\n",
    "if sns_major > 0 or sns_minor >= 11:\n",
    "    sns.histplot(all_df.pKa, kde=True, stat='density')\n",
    "else:\n",
    "    sns.distplot(all_df.pKa)\n",
    "plt.ylabel('Density')\n",
    "plt.xlabel('p$K$ₐ')\n",
    "plt.title('Monoprotic p$K$ₐ Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Descriptors and Fingerprints\n",
    "- Selected RDKit descriptors (see first notebook cell)\n",
    "- Morgan FP with radius=3 and useFeatures=True (FMorgan3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs, fmorgan3, descs_fmorgan3 = calc_x_data(all_df.ROMol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training Random Forest, Support Vector Machine (two configurations) and Multilayer Perceptron (three configurations)\n",
    "#### Using the following training sets with 5-fold cross-validation (shuffled)\n",
    "1. RDKit descriptor set\n",
    "2. FMorgan3\n",
    "3. RDKit descriptor set + FMorgan3\n",
    "4. RDKit descriptor set (standard scaled)\n",
    "5. FMorgan3 (standard scaled)\n",
    "6. RDKit descriptor set + FMorgan3 (standard scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 24\n",
    "\n",
    "est_jobs = 12\n",
    "verbose = False\n",
    "\n",
    "y_train = all_df.pKa.values\n",
    "desc_sets = list(zip([descs, fmorgan3, descs_fmorgan3] * 2, \n",
    "                     [False] * 3 + [True] * 3, \n",
    "                     ['Desc', 'FMorgan3', 'Desc_FMorgan3', 'Desc_scaled', 'FMorgan3_scaled', 'Desc_FMorgan3_scaled']))\n",
    "\n",
    "models = ddict(odict)  # estimator => training set => [model, scaler]\n",
    "\n",
    "def train_all_sets(est_cls, params, name):\n",
    "    for x_data, scaled, set_name in desc_sets:\n",
    "        models[name][set_name] = train_cv_model(est_cls, x_data, y_train, params, seed, scaled=scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_score_board(name):\n",
    "    print(f'{name} CV Scores:')\n",
    "    for ts, (m, s) in models[name].items():\n",
    "        print(f'\\t{ts}')\n",
    "        for k, v in m.cv_scores.items():\n",
    "            print(f'\\t\\t- {k}: {np.mean(v):.3f} ± {np.std(v):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### RandomForest (n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cls = RandomForestRegressor\n",
    "rf_params = dict(n_estimators=1000, n_jobs=est_jobs, verbose=verbose, random_state=seed)\n",
    "name = 'RandomForest (n_estimators=1000)'\n",
    "\n",
    "train_all_sets(est_cls, rf_params, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### SupportVectorMachine (gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cls = SVR\n",
    "svr_params = dict(cache_size=4096, verbose=verbose)\n",
    "name = 'SupportVectorMachine (gamma=\"scale\")'\n",
    "\n",
    "train_all_sets(est_cls, svr_params, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### SupportVectorMachine (gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cls = SVR\n",
    "svr_params = dict(cache_size=4096, verbose=verbose, gamma='auto')\n",
    "name = 'SupportVectorMachine (gamma=\"auto\")'\n",
    "\n",
    "train_all_sets(est_cls, svr_params, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Multi Layer Perceptron (early_stopping=False, hidden_layer_sizes=(500, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cls = MLPRegressor\n",
    "mlp_params = dict(hidden_layer_sizes=(500, 500), verbose=verbose, random_state=seed)\n",
    "name = 'Multi Layer Perceptron (early_stopping=False, hidden_layer_sizes=(500, 500))'\n",
    "\n",
    "train_all_sets(est_cls, mlp_params, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Multi Layer Perceptron (early_stopping=True, hidden_layer_sizes=(500, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cls = MLPRegressor\n",
    "mlp_params = dict(hidden_layer_sizes=(500, 500), verbose=verbose, random_state=seed, early_stopping=True)\n",
    "name = 'Multi Layer Perceptron (early_stopping=True, hidden_layer_sizes=(500, 500))'\n",
    "\n",
    "train_all_sets(est_cls, mlp_params, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Multi Layer Perceptron (early_stopping=True, hidden_layer_sizes=(250, 250, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cls = MLPRegressor\n",
    "mlp_params = dict(hidden_layer_sizes=(250, 250, 250), verbose=verbose, random_state=seed, early_stopping=True)\n",
    "name = 'Multi Layer Perceptron (early_stopping=True, hidden_layer_sizes=(250, 250, 250))'\n",
    "\n",
    "train_all_sets(est_cls, mlp_params, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### XGradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cls = xgb.XGBRegressor\n",
    "xgb_params = dict(verbosity=2 if verbose else 0, random_state=seed, n_jobs=est_jobs)\n",
    "name = 'XGradientBoost'\n",
    "\n",
    "train_all_sets(est_cls, xgb_params, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Predicting external testsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novartis_testset = PandasTools.LoadSDF('datasets/novartis_cleaned_mono_unique_notraindata.sdf').set_index('ID', verify_integrity=True)\n",
    "avlilumove_testset = PandasTools.LoadSDF('datasets/AvLiLuMoVe_cleaned_mono_unique_notraindata.sdf').set_index('ID', verify_integrity=True)\n",
    "len(novartis_testset), len(avlilumove_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_nov, fmorgan3_nov, descs_fmorgan3_nov = calc_x_data(novartis_testset.ROMol)\n",
    "descs_avl, fmorgan3_avl, descs_fmorgan3_avl = calc_x_data(avlilumove_testset.ROMol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting with all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_models(desc, fp, both, true_vals):\n",
    "    res = ddict(list)\n",
    "    for conf, desc_set in models.items():\n",
    "        for ts, (m, s) in desc_set.items():\n",
    "            \n",
    "            x_test = both if ts.startswith('Desc_FMorgan3') else fp if ts.startswith('FMorgan3') else desc\n",
    "            if s:\n",
    "                x_test = s.transform(x_test)\n",
    "            pred = m.predict(x_test)\n",
    "            res['Model'].append(conf)\n",
    "            res['Trainset'].append(ts)\n",
    "            res['MAE'].append(mean_absolute_error(true_vals, pred))\n",
    "            res['RMSE'].append(rmse(true_vals, pred))\n",
    "            res['R2'].append(r2_score(true_vals, pred))\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_nov = test_all_models(descs_nov, fmorgan3_nov, descs_fmorgan3_nov, novartis_testset.pKa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_nov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_avl = test_all_models(descs_avl, fmorgan3_avl, descs_fmorgan3_avl, avlilumove_testset.pKa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res_df_avl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
